{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../datasets/Final_Upwork_Dataset.csv.zip', compression='zip')\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocess text function\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
    "    text = text.lower()              # Convert to lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "# Ensure 'Description' has no NaN values before processing\n",
    "df['Description'] = df['Description'].fillna(\"\")\n",
    "df['processed_description'] = df['Description'].apply(preprocess_text)\n",
    "\n",
    "# Function to extract duration in weeks from 'Time_Limitation'\n",
    "def extract_duration_weeks(time_limit):\n",
    "    if pd.isna(time_limit):\n",
    "        return None\n",
    "    time_limit = time_limit.lower()\n",
    "    match = re.search(r'(\\d+)\\s*to\\s*(\\d+)\\s*months', time_limit)\n",
    "    if match:\n",
    "        min_weeks = int(match.group(1)) * 4\n",
    "        max_weeks = int(match.group(2)) * 4\n",
    "        return (min_weeks, max_weeks)\n",
    "    if \"less than 30 hrs/week\" in time_limit:\n",
    "        return (1, 12)\n",
    "    if \"more than 30 hrs/week\" in time_limit:\n",
    "        return (12, 52)\n",
    "    return None\n",
    "\n",
    "# Apply duration extraction\n",
    "df['Duration_Weeks'] = df['Time_Limitation'].apply(extract_duration_weeks)\n",
    "\n",
    "# Process Start_rate and filter out rows with zero value\n",
    "df['Start_rate'] = pd.to_numeric(df['Start_rate'], errors='coerce').fillna(0)\n",
    "df = df[df['Start_rate'] > 0]\n",
    "\n",
    "# Precompute TF-IDF matrix for job descriptions (using bi-grams)\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 2))\n",
    "job_vectors = vectorizer.fit_transform(df['processed_description'])\n",
    "\n",
    "def find_top_matches(client_input, df, top_n=50, scaling_factor=10):\n",
    "    # Prepare client text with extra weight for the title (repeat it)\n",
    "    client_text = (client_input['title'] + \" \") * 2 + client_input['description'] + \" \" + client_input['skills']\n",
    "    client_text = preprocess_text(client_text)\n",
    "    # Transform the client text using the pre-fitted vectorizer\n",
    "    client_vector = vectorizer.transform([client_text])\n",
    "    # Compute raw cosine similarity between the client vector and all job vectors\n",
    "    raw_similarities = cosine_similarity(client_vector, job_vectors).flatten()\n",
    "    # Multiply by the scaling factor, then clip to ensure values don't exceed 1\n",
    "    scaled_similarities = np.clip(raw_similarities * scaling_factor, 0, 1)\n",
    "    # Create a copy of the dataframe and attach the scaled similarity scores\n",
    "    df_local = df.copy()\n",
    "    df_local['similarity'] = scaled_similarities\n",
    "    # Do not filter by experienceâ€”focus is on title, description, and skills.\n",
    "    filtered_df = df_local.copy()\n",
    "    client_duration = client_input['duration']\n",
    "    client_budget = client_input['budget']\n",
    "    # Drop rows with missing Duration_Weeks or Start_rate values\n",
    "    filtered_df = filtered_df.dropna(subset=['Duration_Weeks', 'Start_rate'])\n",
    "    # Filter based on the client's desired duration fitting within the job's duration range\n",
    "    filtered_df = filtered_df[filtered_df['Duration_Weeks'].apply(lambda x: x[0] <= client_duration <= x[1])]\n",
    "    # Estimate hourly budget (assuming a 40-hour work week)\n",
    "    total_hours = client_duration * 40  \n",
    "    estimated_hourly_budget = client_budget / total_hours if total_hours > 0 else 0\n",
    "    # Calculate budget difference for further ranking\n",
    "    filtered_df['budget_diff'] = abs(filtered_df['Start_rate'] - estimated_hourly_budget)\n",
    "    # Create an ordering for experience: Expert first, then Intermediate, then others.\n",
    "    experience_order = {'expert': 1, 'intermediate': 2, 'beginner': 3}\n",
    "    # Map the experience levels from the dataset (assumed to be in 'EX_level_demand')\n",
    "    filtered_df['exp_order'] = filtered_df['EX_level_demand'].str.lower().map(experience_order)\n",
    "    # If experience is missing or not in the mapping, assign a high order value so they come last.\n",
    "    filtered_df['exp_order'] = filtered_df['exp_order'].fillna(99)\n",
    "    # Sort results: first by similarity (descending), then by experience order (ascending), then by budget difference (ascending)\n",
    "    top_matches = filtered_df.sort_values(by=['similarity', 'exp_order', 'budget_diff'], ascending=[False, True, True]).head(top_n)\n",
    "    return top_matches\n",
    "\n",
    "@app.route('/api/python', methods=['POST'])\n",
    "def process_client_input():\n",
    "    client_input = request.json\n",
    "    top_matches = find_top_matches(client_input, df)\n",
    "    return jsonify(top_matches.to_dict(orient='records'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
